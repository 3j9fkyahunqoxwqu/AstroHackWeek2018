{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from [Pytorch tutorial for Deep Learning researchers](https://github.com/yunjey/pytorch-tutorial) (Yunvey Choi, 2018).\n",
    "\n",
    "Used as part of Deep Learning, Gilles Louppe, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "X, y = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b694b0630>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[6, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0967 -0.0703 -0.0273  ...  -0.1472 -0.1537  0.4669\n",
       "-0.0404 -0.1759 -0.3237  ...  -0.0746 -0.2314  0.0316\n",
       " 0.1587  0.1899  0.0718  ...  -0.0636  0.1938  0.3452\n",
       "          ...             â‹±             ...          \n",
       " 0.2059 -0.1360  0.0652  ...  -0.2467 -0.2339  0.3105\n",
       "-0.2478  0.3497  0.0390  ...  -0.1243 -0.1043  0.5931\n",
       " 0.0822 -0.1064 -0.1653  ...  -0.1464 -0.2468  0.4525\n",
       "[torch.FloatTensor of size 100x10]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Variable(X.view(-1, 28*28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [100/600], Loss: 2.2050\n",
      "Epoch: [1/5], Step: [200/600], Loss: 2.1026\n",
      "Epoch: [1/5], Step: [300/600], Loss: 2.0243\n",
      "Epoch: [1/5], Step: [400/600], Loss: 1.9385\n",
      "Epoch: [1/5], Step: [500/600], Loss: 1.8524\n",
      "Epoch: [1/5], Step: [600/600], Loss: 1.8225\n",
      "Epoch: [2/5], Step: [100/600], Loss: 1.7373\n",
      "Epoch: [2/5], Step: [200/600], Loss: 1.7237\n",
      "Epoch: [2/5], Step: [300/600], Loss: 1.5928\n",
      "Epoch: [2/5], Step: [400/600], Loss: 1.5756\n",
      "Epoch: [2/5], Step: [500/600], Loss: 1.5811\n",
      "Epoch: [2/5], Step: [600/600], Loss: 1.4763\n",
      "Epoch: [3/5], Step: [100/600], Loss: 1.4795\n",
      "Epoch: [3/5], Step: [200/600], Loss: 1.4147\n",
      "Epoch: [3/5], Step: [300/600], Loss: 1.3265\n",
      "Epoch: [3/5], Step: [400/600], Loss: 1.3713\n",
      "Epoch: [3/5], Step: [500/600], Loss: 1.2384\n",
      "Epoch: [3/5], Step: [600/600], Loss: 1.2601\n",
      "Epoch: [4/5], Step: [100/600], Loss: 1.1688\n",
      "Epoch: [4/5], Step: [200/600], Loss: 1.2238\n",
      "Epoch: [4/5], Step: [300/600], Loss: 1.1832\n",
      "Epoch: [4/5], Step: [400/600], Loss: 1.0891\n",
      "Epoch: [4/5], Step: [500/600], Loss: 1.1139\n",
      "Epoch: [4/5], Step: [600/600], Loss: 1.0922\n",
      "Epoch: [5/5], Step: [100/600], Loss: 1.2011\n",
      "Epoch: [5/5], Step: [200/600], Loss: 1.0917\n",
      "Epoch: [5/5], Step: [300/600], Loss: 1.0032\n",
      "Epoch: [5/5], Step: [400/600], Loss: 1.0608\n",
      "Epoch: [5/5], Step: [500/600], Loss: 0.9956\n",
      "Epoch: [5/5], Step: [600/600], Loss: 1.0304\n"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                  % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
