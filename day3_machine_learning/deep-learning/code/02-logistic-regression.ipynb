{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from [Pytorch tutorial for Deep Learning researchers](https://github.com/yunjey/pytorch-tutorial) (Yunvey Choi, 2018).\n",
    "\n",
    "Used as part of Deep Learning, Gilles Louppe, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "X, y = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa0a6e7f198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1325,  0.0991, -0.1516, -0.0527, -0.2537, -0.1245,  0.0726,\n",
       "         -0.0568, -0.0388,  0.3154],\n",
       "        [ 0.0260,  0.0012, -0.3698,  0.0418, -0.0589, -0.3042,  0.0863,\n",
       "          0.0184,  0.1338,  0.0838],\n",
       "        [ 0.0024, -0.3745,  0.2404, -0.0384, -0.0415,  0.0632,  0.3163,\n",
       "         -0.0979,  0.1467, -0.3185],\n",
       "        [ 0.0944, -0.1839,  0.2336, -0.1296, -0.2289, -0.0484,  0.3947,\n",
       "         -0.1442,  0.0718, -0.2681],\n",
       "        [ 0.1373, -0.0372, -0.0423, -0.0940,  0.1559, -0.2193,  0.2472,\n",
       "          0.2086,  0.0982,  0.0668],\n",
       "        [ 0.1252, -0.1126, -0.1416,  0.0267,  0.3008, -0.1437,  0.3418,\n",
       "          0.2136,  0.0979, -0.0337],\n",
       "        [ 0.1057, -0.1640, -0.0205, -0.1587, -0.0592,  0.0025,  0.1679,\n",
       "          0.0129, -0.0079,  0.0962],\n",
       "        [ 0.0773, -0.0738, -0.0123, -0.1396,  0.0871,  0.0904,  0.3767,\n",
       "          0.0911, -0.2165,  0.0037],\n",
       "        [ 0.1297, -0.2408, -0.1751, -0.0880,  0.3189, -0.0917,  0.4033,\n",
       "          0.0853, -0.1524,  0.0994],\n",
       "        [-0.0062,  0.0550, -0.1177,  0.0749,  0.1718, -0.2502,  0.3233,\n",
       "          0.0705,  0.1437, -0.0677],\n",
       "        [ 0.2304,  0.0497, -0.2427, -0.3507,  0.0493, -0.4357,  0.2966,\n",
       "         -0.1888, -0.0415,  0.2309],\n",
       "        [ 0.0833, -0.1575, -0.1062,  0.0752,  0.1172, -0.0271,  0.3332,\n",
       "          0.1198,  0.0310, -0.3325],\n",
       "        [-0.0267,  0.2028,  0.1419,  0.0400,  0.0174, -0.1210,  0.4857,\n",
       "         -0.0481,  0.0532, -0.0286],\n",
       "        [ 0.1545, -0.3143, -0.0685, -0.0255,  0.2969,  0.3137,  0.5451,\n",
       "          0.0715, -0.1217, -0.0235],\n",
       "        [ 0.1414,  0.1479,  0.0668,  0.0889,  0.1714, -0.1713,  0.4868,\n",
       "         -0.0045,  0.0031, -0.1340],\n",
       "        [-0.0314, -0.0756, -0.0420,  0.0635,  0.0340, -0.2217,  0.4421,\n",
       "         -0.0222, -0.1081, -0.0026],\n",
       "        [ 0.0422, -0.2825, -0.0968,  0.1684, -0.3617, -0.0081,  0.0882,\n",
       "         -0.2426, -0.1996, -0.0191],\n",
       "        [ 0.2645, -0.1838, -0.0221,  0.1467,  0.1220, -0.0689,  0.3687,\n",
       "          0.1013, -0.1275, -0.0612],\n",
       "        [-0.0526, -0.3636, -0.0740, -0.1016,  0.1190, -0.0032,  0.3037,\n",
       "         -0.2824, -0.1226, -0.0980],\n",
       "        [-0.0538, -0.0686,  0.0750, -0.0149,  0.1355,  0.0648,  0.1311,\n",
       "         -0.0193,  0.0362,  0.0208],\n",
       "        [-0.1352, -0.1092, -0.1824,  0.0705,  0.2328, -0.3616,  0.1956,\n",
       "          0.1975,  0.0096, -0.0339],\n",
       "        [ 0.0070, -0.1221,  0.0973, -0.1260,  0.1811, -0.0372,  0.3281,\n",
       "          0.0413, -0.1373,  0.0235],\n",
       "        [-0.0607, -0.2098, -0.0373,  0.0129,  0.3201, -0.0609,  0.4398,\n",
       "         -0.2701, -0.0108, -0.0693],\n",
       "        [ 0.2754, -0.1549, -0.1648,  0.0582, -0.1321, -0.0270,  0.3223,\n",
       "          0.1099,  0.0819,  0.1074],\n",
       "        [-0.0383, -0.1035, -0.0086,  0.0552,  0.3787, -0.1229,  0.5267,\n",
       "         -0.3189,  0.2323,  0.0172],\n",
       "        [ 0.0980, -0.1409, -0.2657, -0.1920,  0.2139, -0.3423,  0.2797,\n",
       "          0.1458, -0.0344,  0.1544],\n",
       "        [-0.0859, -0.3401, -0.2127,  0.0596,  0.1926, -0.1742,  0.2216,\n",
       "         -0.0024, -0.0099,  0.0646],\n",
       "        [ 0.2860, -0.1350, -0.2187, -0.0134,  0.1290, -0.0440,  0.3494,\n",
       "          0.0182,  0.1501, -0.0330],\n",
       "        [ 0.1352, -0.1186, -0.0342, -0.1053,  0.3067,  0.1792,  0.5858,\n",
       "          0.0695, -0.2588, -0.0374],\n",
       "        [-0.0466, -0.0825, -0.0509,  0.0363,  0.1817, -0.0492,  0.0535,\n",
       "          0.1798, -0.4382,  0.2359],\n",
       "        [ 0.1406,  0.0959, -0.2605, -0.0027,  0.0900, -0.1563,  0.3919,\n",
       "          0.1100, -0.0360, -0.0238],\n",
       "        [ 0.1198, -0.0772, -0.0786,  0.0319, -0.0119, -0.0648,  0.1954,\n",
       "          0.0648,  0.1427,  0.0972],\n",
       "        [ 0.1504, -0.0792,  0.0777,  0.0838,  0.0075, -0.2269,  0.3641,\n",
       "          0.0558, -0.0959,  0.0007],\n",
       "        [ 0.1558, -0.2005, -0.0201,  0.0712,  0.0281, -0.1666,  0.2382,\n",
       "          0.0933,  0.1468,  0.0408],\n",
       "        [-0.2604, -0.2782, -0.3777,  0.0674,  0.2622,  0.0585,  0.0361,\n",
       "         -0.0520, -0.0360, -0.0375],\n",
       "        [-0.0466,  0.1530, -0.3802,  0.2509,  0.2238, -0.5763,  0.2318,\n",
       "          0.3004,  0.1511,  0.0090],\n",
       "        [ 0.3752, -0.0063, -0.1478,  0.0318, -0.0183, -0.1953,  0.4052,\n",
       "          0.0859, -0.3368,  0.1337],\n",
       "        [ 0.0384, -0.1348, -0.1115, -0.0767,  0.0870, -0.3189,  0.1511,\n",
       "          0.1197,  0.0453,  0.0442],\n",
       "        [ 0.2508,  0.2260, -0.2403,  0.0067, -0.1733, -0.3167,  0.1981,\n",
       "          0.1293,  0.0305,  0.3319],\n",
       "        [ 0.0725, -0.0933, -0.1288,  0.0493,  0.0739, -0.2865,  0.2559,\n",
       "          0.2234, -0.0038,  0.0503],\n",
       "        [-0.0179, -0.0643, -0.1963, -0.0177,  0.1458,  0.0137,  0.1269,\n",
       "          0.2178,  0.0788, -0.0702],\n",
       "        [-0.0709, -0.2242, -0.0505,  0.0755, -0.3488, -0.0362, -0.0027,\n",
       "         -0.1735,  0.0043, -0.0844],\n",
       "        [ 0.0940, -0.0822,  0.0493,  0.0325,  0.3742, -0.1493,  0.2949,\n",
       "          0.3137, -0.0431, -0.0221],\n",
       "        [ 0.2481, -0.1196,  0.0262, -0.0180, -0.0573, -0.2989,  0.6530,\n",
       "          0.0469, -0.0626, -0.3580],\n",
       "        [ 0.1357, -0.0533,  0.1379, -0.1959, -0.1102, -0.1775,  0.2627,\n",
       "         -0.2074, -0.0819,  0.0061],\n",
       "        [ 0.0631,  0.0610, -0.1069, -0.0900,  0.0958,  0.0203,  0.0528,\n",
       "         -0.1732, -0.2006, -0.1093],\n",
       "        [ 0.1679, -0.0013, -0.0285,  0.1178,  0.4906, -0.4410,  0.5109,\n",
       "         -0.0859,  0.0173,  0.1181],\n",
       "        [ 0.1498,  0.0421,  0.1011, -0.1140, -0.1510, -0.2112,  0.1137,\n",
       "         -0.1083, -0.0679, -0.0373],\n",
       "        [ 0.1685, -0.2691, -0.0618, -0.0485,  0.0010, -0.1668,  0.1744,\n",
       "          0.0835,  0.2546, -0.1459],\n",
       "        [ 0.3291, -0.1876, -0.2096,  0.0329,  0.0054,  0.0073,  0.4862,\n",
       "         -0.2501, -0.1004, -0.2485],\n",
       "        [ 0.0952, -0.1918,  0.0067,  0.0509,  0.1450, -0.2711,  0.3826,\n",
       "         -0.0645,  0.0206, -0.1967],\n",
       "        [ 0.0787, -0.1318,  0.1498, -0.2003,  0.3270, -0.1256,  0.3826,\n",
       "         -0.3708, -0.0212,  0.0952],\n",
       "        [ 0.1616, -0.1286,  0.0057,  0.1012,  0.0070, -0.0952,  0.2231,\n",
       "          0.0647,  0.0616,  0.0230],\n",
       "        [-0.0979, -0.1183, -0.4886,  0.2421, -0.2043, -0.5515,  0.3852,\n",
       "         -0.0062, -0.1534,  0.1205],\n",
       "        [-0.0145, -0.2483, -0.0468, -0.2021,  0.3213,  0.1515,  0.5332,\n",
       "         -0.0232,  0.1553, -0.2590],\n",
       "        [ 0.2350, -0.3131, -0.1249,  0.0950,  0.2147, -0.1110,  0.4645,\n",
       "         -0.2760, -0.0515, -0.0879],\n",
       "        [ 0.1422, -0.3085, -0.3623, -0.0039,  0.4221, -0.0440,  0.5080,\n",
       "          0.1160,  0.0574,  0.2204],\n",
       "        [-0.0078, -0.2408, -0.4178,  0.0487,  0.0290, -0.4625,  0.0983,\n",
       "         -0.0280, -0.0094,  0.0623],\n",
       "        [-0.0300,  0.0466,  0.1575, -0.0638, -0.0057, -0.1353,  0.2006,\n",
       "         -0.0368, -0.0625,  0.0068],\n",
       "        [-0.0744, -0.2861, -0.0099,  0.0331,  0.1092,  0.0461,  0.3174,\n",
       "         -0.2625, -0.0070, -0.1070],\n",
       "        [ 0.2436, -0.1999, -0.1012, -0.0662,  0.4465, -0.2155,  0.5977,\n",
       "         -0.0119,  0.1738,  0.1049],\n",
       "        [ 0.0500, -0.3782, -0.0709, -0.4252,  0.2335, -0.2317,  0.3769,\n",
       "         -0.2302,  0.0913,  0.0691],\n",
       "        [ 0.1450, -0.0729, -0.2323, -0.0671, -0.0780, -0.0080,  0.3799,\n",
       "          0.1250, -0.1622,  0.0543],\n",
       "        [ 0.0045, -0.3497, -0.2955, -0.0407,  0.4994,  0.0055,  0.5581,\n",
       "          0.0908, -0.0391, -0.1099],\n",
       "        [ 0.3471, -0.1843, -0.1790,  0.0768,  0.0395, -0.0930,  0.3162,\n",
       "          0.0750,  0.1484, -0.2375],\n",
       "        [ 0.1213,  0.1370,  0.0481,  0.0934,  0.0430, -0.2598,  0.2136,\n",
       "          0.0852, -0.1225,  0.0043],\n",
       "        [ 0.3735, -0.1840, -0.1500,  0.0605, -0.0203, -0.1816,  0.4054,\n",
       "          0.1855,  0.0364,  0.1453],\n",
       "        [ 0.2282, -0.0861,  0.0357, -0.2050, -0.1085,  0.1141,  0.1781,\n",
       "          0.0786, -0.0448,  0.0626],\n",
       "        [ 0.2107,  0.0543, -0.0862,  0.2836,  0.1701, -0.2656,  0.3725,\n",
       "          0.0407, -0.1658,  0.1480],\n",
       "        [-0.0114, -0.2325,  0.0133, -0.1767, -0.2051, -0.0685,  0.0132,\n",
       "         -0.3043,  0.1505,  0.0954],\n",
       "        [-0.0278, -0.0069, -0.2180,  0.0497,  0.4242, -0.1481,  0.1714,\n",
       "          0.1560,  0.1472,  0.3053],\n",
       "        [ 0.1611, -0.0327, -0.1732,  0.0250,  0.4683, -0.1116,  0.7839,\n",
       "         -0.0302,  0.0325,  0.0414],\n",
       "        [ 0.0753, -0.1666, -0.1234, -0.2487,  0.0282, -0.2033,  0.5370,\n",
       "          0.0995, -0.1848,  0.3245],\n",
       "        [ 0.3093, -0.0261, -0.1342,  0.0007,  0.1381, -0.1609,  0.4264,\n",
       "          0.1636, -0.3549,  0.3182],\n",
       "        [ 0.0808, -0.1988, -0.0466, -0.2203, -0.1551,  0.0331,  0.2766,\n",
       "         -0.2805, -0.0034, -0.1235],\n",
       "        [ 0.0581,  0.0506, -0.1462,  0.1326,  0.2735, -0.5529,  0.2243,\n",
       "          0.0767,  0.0846,  0.1535],\n",
       "        [ 0.0189,  0.0494, -0.0260,  0.0264,  0.2610, -0.1427,  0.3296,\n",
       "         -0.1657,  0.1250,  0.0649],\n",
       "        [ 0.0683, -0.0953, -0.2698,  0.0760,  0.1748, -0.4484, -0.0238,\n",
       "          0.1142,  0.0050,  0.1687],\n",
       "        [ 0.0731, -0.0312, -0.1890, -0.0214,  0.2489, -0.0824,  0.2435,\n",
       "          0.0423,  0.0470,  0.1974],\n",
       "        [ 0.3208, -0.2389, -0.0671, -0.2547, -0.1040, -0.0918,  0.6060,\n",
       "         -0.2076, -0.0962, -0.1424],\n",
       "        [ 0.0875, -0.1364, -0.0956, -0.0749,  0.1312,  0.1801,  0.2431,\n",
       "          0.0844, -0.1482,  0.0711],\n",
       "        [ 0.0795, -0.1246, -0.0669, -0.1323,  0.1112, -0.1453,  0.3070,\n",
       "         -0.0030, -0.0745, -0.1828],\n",
       "        [ 0.2004, -0.2521, -0.2351, -0.0159,  0.2970, -0.1381,  0.3690,\n",
       "         -0.2502, -0.1726,  0.1817],\n",
       "        [ 0.1056, -0.1158,  0.0538, -0.1145,  0.0597, -0.2427,  0.2663,\n",
       "          0.0834,  0.0907, -0.0411],\n",
       "        [-0.1252, -0.0950,  0.1246,  0.0096,  0.1793,  0.1949,  0.2959,\n",
       "          0.0533,  0.2096,  0.1172],\n",
       "        [ 0.1186, -0.1452,  0.0018, -0.1480,  0.0152, -0.1441,  0.4049,\n",
       "         -0.0977,  0.1332, -0.2156],\n",
       "        [-0.0025, -0.0946,  0.0943, -0.0933,  0.2399, -0.1458,  0.3767,\n",
       "         -0.0410,  0.1374, -0.3724],\n",
       "        [ 0.0984, -0.1070, -0.1528, -0.0359,  0.0274, -0.1127,  0.2393,\n",
       "          0.1874,  0.0049, -0.0132],\n",
       "        [-0.1596, -0.1298, -0.0950, -0.0521, -0.0173, -0.0655,  0.2596,\n",
       "         -0.2071,  0.0338, -0.1125],\n",
       "        [-0.0814, -0.0221, -0.2203,  0.1226,  0.2354, -0.0590,  0.0537,\n",
       "          0.1345,  0.0463, -0.0364],\n",
       "        [ 0.2454, -0.0833, -0.0702,  0.0936, -0.0082, -0.0747,  0.3367,\n",
       "          0.1313,  0.0273,  0.0373],\n",
       "        [-0.0923, -0.2910, -0.1318,  0.0222,  0.2805,  0.0081,  0.3511,\n",
       "          0.0011,  0.2309, -0.1833],\n",
       "        [ 0.2807, -0.0345, -0.0120, -0.2794,  0.0633, -0.3049,  0.2383,\n",
       "         -0.0380, -0.0918,  0.3178],\n",
       "        [-0.0462, -0.1842, -0.1540, -0.1391,  0.3892, -0.3813,  0.1849,\n",
       "         -0.1413, -0.0600,  0.3998],\n",
       "        [ 0.1865, -0.0342, -0.1334,  0.0384,  0.0635, -0.2634,  0.3603,\n",
       "          0.1641,  0.1802,  0.0709],\n",
       "        [ 0.2696,  0.0192, -0.0166, -0.2650,  0.3256,  0.1280,  0.2703,\n",
       "          0.1685, -0.0175,  0.2901],\n",
       "        [ 0.0931, -0.0791, -0.1497,  0.0544,  0.0637, -0.0063,  0.1969,\n",
       "         -0.0027,  0.0283, -0.1071],\n",
       "        [ 0.2493, -0.1280,  0.0674, -0.0996,  0.1913,  0.1928,  0.3727,\n",
       "          0.1438, -0.0962,  0.1500],\n",
       "        [-0.0284, -0.0628,  0.0845, -0.0398, -0.0288, -0.1785,  0.0378,\n",
       "          0.0174,  0.0247, -0.1174],\n",
       "        [ 0.2425, -0.2800, -0.0919, -0.0078,  0.2681, -0.2015,  0.3930,\n",
       "         -0.2009, -0.1049,  0.4932]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Variable(X.view(-1, 28*28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [100/600], Loss: 2.2372\n",
      "Epoch: [1/5], Step: [200/600], Loss: 2.1125\n",
      "Epoch: [1/5], Step: [300/600], Loss: 2.0064\n",
      "Epoch: [1/5], Step: [400/600], Loss: 1.9765\n",
      "Epoch: [1/5], Step: [500/600], Loss: 1.9064\n",
      "Epoch: [1/5], Step: [600/600], Loss: 1.7318\n",
      "Epoch: [2/5], Step: [100/600], Loss: 1.7057\n",
      "Epoch: [2/5], Step: [200/600], Loss: 1.7034\n",
      "Epoch: [2/5], Step: [300/600], Loss: 1.6212\n",
      "Epoch: [2/5], Step: [400/600], Loss: 1.5126\n",
      "Epoch: [2/5], Step: [500/600], Loss: 1.5190\n",
      "Epoch: [2/5], Step: [600/600], Loss: 1.5080\n",
      "Epoch: [3/5], Step: [100/600], Loss: 1.3161\n",
      "Epoch: [3/5], Step: [200/600], Loss: 1.4259\n",
      "Epoch: [3/5], Step: [300/600], Loss: 1.2661\n",
      "Epoch: [3/5], Step: [400/600], Loss: 1.3531\n",
      "Epoch: [3/5], Step: [500/600], Loss: 1.3033\n",
      "Epoch: [3/5], Step: [600/600], Loss: 1.2448\n",
      "Epoch: [4/5], Step: [100/600], Loss: 1.1509\n",
      "Epoch: [4/5], Step: [200/600], Loss: 1.1958\n",
      "Epoch: [4/5], Step: [300/600], Loss: 1.2482\n",
      "Epoch: [4/5], Step: [400/600], Loss: 1.1523\n",
      "Epoch: [4/5], Step: [500/600], Loss: 1.0056\n",
      "Epoch: [4/5], Step: [600/600], Loss: 1.0569\n",
      "Epoch: [5/5], Step: [100/600], Loss: 1.0690\n",
      "Epoch: [5/5], Step: [200/600], Loss: 1.1516\n",
      "Epoch: [5/5], Step: [300/600], Loss: 1.1371\n",
      "Epoch: [5/5], Step: [400/600], Loss: 1.0047\n",
      "Epoch: [5/5], Step: [500/600], Loss: 1.0239\n",
      "Epoch: [5/5], Step: [600/600], Loss: 1.0436\n"
     ]
    }
   ],
   "source": [
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                  % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
